{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: 2.0-LeNet-5-MNIST.ipynb\n",
    "# Author: Eyosyas Dagnachew\n",
    "# Description: Train LeNet-5 model on MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters/Hyperparameters\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"../../data\", \n",
    "                                           train=True, \n",
    "                                           transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                           download=False)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"../../data\",\n",
    "                                          train=False,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                          download=False)\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    '''\n",
    "    Input: 32x32 pixel image in the paper, but 28x28 in the dataset\n",
    "           The paper mentions that \"[32x32] is significantly larger than the largest character in the\n",
    "           database (at most 20x20 pixels centered in a 28x28 field). This might explain why the \n",
    "           the images in this dataset have been cropped to 28x28.\n",
    "           \n",
    "           Using 2D convolution because the input is technically a 3D (32x32x1) image.\n",
    "           \n",
    "    Output: 10\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Layer C1: conv layer with 6 28x28 feature maps with 5x5 kernels \n",
    "        #           parameters and connections: 156 trainable parameters, 122304 connections\n",
    "        #           notes: padding=2 because the original images were 32x32 but this dataset contains 28x28 images (2 pixels removed \n",
    "        #                  from all sides), so we have to make up for the removed pixels but adding a padding of 2 on all sides\n",
    "        #           in: 32x32x1, out: 28x28x6\n",
    "        self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)    \n",
    "        \n",
    "        # Layer S2: sub-sampling (pooling) layer with 6 14x14 feature maps with 2x2 kernels; result are passed to sigmoidal function\n",
    "        #           parameters and connections: 12 trainable parameters, 5800 connections (in the paper);\n",
    "        #                                       0 trainable parameters, 5880 connections (in my implementation, read notes below)\n",
    "        #           notes: \"The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, \n",
    "        #                  and added to a trainable bias.\" This is where the difference between subsampling and pooling comes to play. \n",
    "        #                  Subsampling, as mentioned in the paper, is simply average pooling with learnable weights per feature map. \n",
    "        #                  In the Lua implementation of Torch, there is nn.SpatialSubSampling() but there is no such implementation\n",
    "        #                  for PyTorch, so I will just use average pooling, i.e. AvgPool2d().\n",
    "        #           in: 28x28x6, out: 14x14x6\n",
    "        self.s2 = nn.Sequential(\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2),    # sub-sampling\n",
    "                    nn.Sigmoid()                              # sigmoidal function\n",
    "        )\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LeNet model\n",
    "model = LeNet5(num_classes=NUM_CLASSES).to(device)\n",
    "print(model)\n",
    "\n",
    "# Print the number of parameters\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.numel())    # 6 filters (150 each because 150/6 = 25 and 5x5 = 25 and weight sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
